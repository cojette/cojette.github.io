---
layout: post
title: 데이터로 살펴보는 SF 영화 속 로봇(4)
---

## 자동으로 족보 만들기

### 성격으로 판단해 보자.

일반적으로 영화에 등장하는 로봇의 경우 성격이 확연하게 드러나는 편이다. 아무래도 1편(긴 경우는 영화에서의 시리즈물도 가능하지만 흔치 않다.)짜리에서 이야기가 끝나야 하고, 로봇이 주연인 경우는 사람형 아니면 애니메이션에서나 가능한 이야기일 뿐 더러, 대부분 인간보다 설정이 단순한 경향이 있다. 

그래서 어쩌면 로봇에 대한 설명만으로 자동으로 성격을 구분할 수 있지 않을까...하는 아주 사소한 희망을 걸고 흔히(?) 하는 sentiment analysis를 해 보기로 했다. 마침 샘플 데이터 중에는 imdb의 movie review가 있어서, 이를 트레이닝 데이터로 사용하고, nltk 라이브러리의 NaiveBayes  Classifier 를 사용하여 두 가지로 구분하는 방법을 사용해서 학습시켰다. 

(Naive Bayes 방법은 machine learning 알고리즘 중 많이 사용되는 알고리즘 중 하나로, supervised learning방법 중 하나다. 각 속성이 독립일 경우 해당 속성이 어느 집단에 나타날 경우 어느 쪽으로 분류될 수 있는지 확률을 배당하는 방법으로, 텍스트 분류 시 가장 무난하게 사용되는 방법 중 하나이고, 실제 스팸 필터링에 상당수 사용되는 것으로 알려져 있다. - 물론 문장에서 각 단어들이 '독립적'이냐 하는 이슈가 있지만 스팸의 경우는 워낙 비문과 분절적 단어들이 많기도 하다. 자세한 것은 책이나 웹을 참고..)

![](https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/GxW/image/ZNDJHPFghMT1ATChwbvASg558as.png)

이 무한한 '부정'의 향연...

하지만 생각과는 다르게, 대부분의 로봇이 부정적인 결과가 나왔다. 납득할 수 없지 않나. 물론 많은 SF 영화들이 책보다도 자극적이고 효과적으로 디스토피아를 그리고 있고 많은 로봇이 인간의 주적으로 등장한다. 하지만 일찌기 등장한 재패니메이션의 아톰 같은 로봇은? 최근 빅히어로-6의 베이맥스는? 은근 이런 로봇들도 왕왕 있는데 이렇게 모두 negative로 찍히고 좋은 로봇이 달랑 4명(?) 뿐이라는 게 쉽게 이해가 가지 않는다.

그래서 여러 이유를 추론해 보았다. 물론 'kill', 'war', 'criminal'등의 단어가 많은 곳에서 튀어나오기는 한다. 하지만 이게 다일까? beautiful, love 등의 단어는 다 어디로 간 것이며, 우선 앞에서 살펴 본 10위권 내의 단어들은 일반적으로 어떤 감정적 판단도 보류한다.

여러 가지 고민을 하다가, movie review이므로 positive/negative 로 나눠지는 것이 영화의 평점임을 생각해 내고, imdb의 장르별 평점을 확인해 보았다. (남이 해 놓은 자료를 레퍼런스로 사용하였다)

[Mining IMDB database - summary](http://chipjacks.com/projects/2013/09/24/IMDB-Stats.html)

여기의 가장 위의 통계를 보면 알 수 있지만, Sci-Fi 는 평점 10점 만점에서 4점대로 Horror 다음으로 낮다. 즉 SF의 리뷰의 대다수는 negative 결과를 얻을 것이고, 이는 여기 사용된 단어를 주로 사용한 테스트 데이터에도 그대로 반영될 수밖에 없다.  아쉬운 일이다.

(물론 nltk에서 사용 가능한 다른 트레이닝 셋 역시 사용해 보았으나 이런 경우 포함된 단어가 많이 달라서 제대로 결과를 낼 수 없었음을 미리 밝혀둔다)

### 자동 분류 체계 만들기 (클러스터링)

지금까지는 어떤 기준을 미리 준 후에 그 기준 대로 '구분'을 하거나, 혹은 미리 트레이닝 셋을 마련한 후 이를 기반으로 분류를 했다. 하지만 많은 데이터 분석에 있어서, 어떤 명확한 '답'이 있는 데이터를 분석해야 하는 운 좋은 경우는 실제 생활에서는 매우 어렵다.(알파고도 supervised learning을 기반으로 한다. 정답이 없는 경우도 도전한다지만 아직 거기까지는 오지 않았다) 그래서 이럴 때 활용할 수 있는 unsupervised learning을 활용해서, 이 로봇들을 분류해보고, 분류된 로봇들이 어떤 공통점을 가지고 있는 지를 확인해 보기로 했다.

여러 가지 clustering 방법이 있지만, 여기서는 가장 쉽고 빠르고 단순한 K-means를 사용해 보기로 한다.

(K-means clustering은, 말 그대로 거리 기반으로 K개의 군집을 묶는 방식이다. 계산 및 이해가 용이해서 많이 사용한다.)

![](https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/GxW/image/-xIX9Y2Gtb90oQt-n61y0-bcNwY.png)

![](https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/GxW/image/CsSTn-EhcZD1hIMZuYLKH_oXNn0.png)

무난하게(?) 5개로 분류해 보았다. 결과는 다음과 같다. 대충 어떤 기준으로 사용할 수 있는지, 여기서 사용된 단어들과 로봇들을 확인해 보기로 한다.

![](https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/GxW/image/wkwnpGLxkQrclurTmdlgNm4AvSA.png)

![](https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/GxW/image/nf3PM5mFkJR2JaAeGZiXJqmBCeo.png)

이 기준으로 구분한 영화들을 한 번 그림으로 나타내 보자. 우선 일반적으로 사용하는 matplotlib을 사용해 보았다.

![](https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/GxW/image/CX1tzqY2rVSAUvsI8MPGGQ9ZNoA.png)

![](https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/GxW/image/d-yCdzZrfsI_nRvjZpdg1-knFxw.png)

알록달록 꽤 괜찮게 나오는 것을 볼 수 있다. 하지만 영화들이 많고, 겹치는 단어도 많으며 어쩔 수 없이 영화명을 일부 잘라야 하고 겹치기도 해서 아쉽다. 그래서 클러스터의 크기 등도 같이 표현하면서 인터랙티브하게 나타낼 수 있도록 다시 plotly를 사용해 보기로 했다.

![](https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/GxW/image/uMTjzUonalelcxrj2ebtZuPhSxw.png)

![](https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/GxW/image/2cU2N1LSY74UjslOjZo2_iXyl-4.png)

훨씬 예쁘게(?) 나온 그래프를 확인할 수 있다. 각 포인트에 마우스오버하면 영화 및 단어들도 확인할 수 있다. 

다만 겹치는 단어들이 많아서인지 구분이 확실하지 않다는 것을 알 수 있다. 각 클러스터에 대해 주변의 원을 그려봤을 때 겹치는 부분이 과하게 많다. 실제로는 이런 클러스터는 쓰면 안 되지만, n번의 시도에도 불구하고 구분이 잘 안 되어서 일단 이런 방법도 있다, 하고 소개하는 것으로 마무리한다. 

(사실 이를 위해서는 각 로봇별 주요 단어를 제외하고 쳐내야 깔끔했겠지만, 역시나 데이터 노가다를 하기가 싫어서 접었다.)

(K means외에도 결과가 잘 나오는 것이 있을까 이런저런 시도를 해봤지만 다 망했다는 것을;; 미리 밝혀둔다. 역시 데이터가 깔끔해야 모든 결과도 좋다.)

정리
==

영화에 나온 로봇들을 정리해보자!! 라는 생각 하에 데이터를 긁는 것부터 이런저런 테스트까지 잡다하게 해 보았다. 나름 흥미로운 작업이었고, 물론 이 내용은 '다 아는 것을 그냥 확인한' 정도고 심지어 이런 것도 가능하다 고 말만 하고 결과는 없는 것들도 상당수 있지만 이게 날 데이터 분석의 모습 아닌가 싶기도 하다. 그래도 이 데이터를 기반으로 나중에 필요할 때 이것저것 붙일 수 있지 않을까 하는 생각도 한다.

이래서 데이터 분석은 흥미를 가지고 해야 하며, 흥미가 없으면 나가 떨어지기도 쉽고 대충 하고 말기도 쉬워진다. 더불어 좋은 데이터가 필수다. 바둑이나 체스 같은 게임에서 인공지능이 먼저 사용되는 것도 데이터가 깔끔하고 정답셋이 확실해서다. 실제 데이터를 사용하는 많은 머신 러닝이 산으로 가는 것도 대부분은 데이터의 결함 때문이다. 그래서 데이터 분석의 7-9할은 데이터 클렌징이며 좋은 데이터가 정말 중요하다. 오버해서 말하면 garbage in, garbage out.

그리고 데이터를 다루는 데는 사람의 개입이 별로 필요하지 않으나 이를 어느 정도 보고 판단하고, 어떤 부분을 시각화해서 전달할까 등을 판단하는 것은 사람의 몫이다. 데이터가 제대로인지 아닌지, 무엇을 보정해야 결과가 제대로 나올 지, 이 결과가 제대로 나왔는지 판단하는, 데이터와 받아 보는 대상(~~아직까지는 ~~인간)의 중간자는 아직 데이터를 분석하는 인간이다. 그래서 이를 중간에서 전달할 수 있는 사람의 domain knowledge가 아직까지는 중요하다. 도메인이 확실하고 데이터도 완전히 깨끗하고 알고리즘도 확실하다면 좋겠지만, 실생활의 대부분의 환경은 그렇지 않다. 그래서 데이터 분석을 위해서는 도메인 지식과 데이터 지식을 균형있게 가지고 있는 것도 중요하다. 그래서 좋아하는 것, 잘 아는 것을 분석하는 것이 중요하고, 그래서 취미나 자기 자신에 대한 데이터를 분석하는 것부터 시작하는 것이 데이터 분석에 접근하는 좋은 방법 중 하나라고 생각한다.

==

Source
======

본 내용에 사용한 코드는 다음 github repository 에서 확인할 수 있다. 
해당 repository에 사용한 데이터도 같이 포함되어 있으니 같이 볼 수 있다. 

<https://github.com/cojette/ClusteringRobotsinMovie/blob/master/Classification%20of%20Robots%20in%20Movies.ipynb>
