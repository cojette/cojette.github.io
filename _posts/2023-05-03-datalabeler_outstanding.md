---
layout: post
title: 데이터 라벨러의 명암, 그리고 조심해야 할 것
date: 2023-05-03 13:00:00 +0900
categories: [Data, Concepts]
tags: [데이터, 데이터 라벨링, 데이터 라벨러, 아웃스탠딩]
---

![](https://wp.outstanding.kr/wp-content/uploads/2023/03/01-labelling.jpg)

3, 4월에는 아웃스탠딩에 데이터 라벨러에 대한 글을 썼습니다. 

## 데이터 라벨러의 명과 암

[링크](https://outstanding.kr/datalaber20230314)

여기저기서 데이터 라벨링 교육과정이 생기는 것을 보고 써 본 글입니다.
데이터 라벨링. 단어 그대로 데이터에 라벨을 다는 작업입니다. 데이터 라벨러는 데이터 라벨링을 하는 직업이죠. 굉장히 직관적인 작업과 직군이라서 얼핏 어렵지 않다고 생각하실 수 있지만, 인공지능 서비스의 급부상과 함께 그 중요성은 나날이 높아지고 있습니다.

1. 데이터 라벨링이랑 작업 자체는 문서 분류나 자료 정리와 유사한 맥락으로, 새롭게 생긴 일은 아닙니다. 요즘은 인공지능의 기계학습에 필요한 데이터를 올바르게 분류하고, 의미나 답을 다는 등 다듬는 작업을 뜻합니다. 인공지능 기술 발전에 핵심적인 역할이라고 해도 과언이 아니죠.
2. 데이터 라벨링의 중요성이 대두되면서 관련 기업이나 사업, 국가 지원이 대폭 늘었습니다. 업무량이 늘어나면서 파트타임이나 풀타임으로 일하는 데이터 라벨러도 급속도로 늘었죠. 자동 라벨링 기술이 발전하고 있지만, 아직까진 한계가 있어서 라벨러란 직업은 계속 각광받을 듯합니다.
3. 동시에 여러 문제점이 눈에 띄기 시작했습니다. 업무 자체가 단순 반복 작업으로 치부되다 보니 임금이 낮고, 근무 환경이 열악합니다. 관련 교육 체계 역시 명확하지 않고요. 전문성을 갖춘 데이터 라벨러를 확보하기 어렵다 보니, 라벨링의 일관성 및 품질에 영향이 갑니다.
4. 무엇보다 교육 및 가이드라인을 체계적으로 갖추지 못한 프로젝트가 많은 탓에 개개인의 주관성 같은 요소가 데이터에 반영될 여지가 있습니다. 이런 데이터는 결과적으로 기계학습 알고리즘의 성능에 직접적으로 영향을 미치죠. 지속 가능한 데이터 라벨링을 위한 대책 마련이 시급한 상황입니다.


## 데이터 라벨링에서 신경써야 할 점

[링크](https://outstanding.kr/datalabelingerror20230417)

데이터 라벨링에 대해서 이야기하다 보니, 예전의 이미지넷 사건이 생각났습니다. 그래서 이 내용을 기반으로 해서 글을 써보았습니다.

주소록에 누군가의 프로필 사진으로 연예인이나 캐릭터 이미지를 등록했더니 사진이 잘못 분류되는 상황을 종종 보셨을 겁니다. 사람 이름이 '라벨' 역할을 했기 때문인데요. 개인 용도라면 작은 해프닝이지만, 커다란 AI시스템에서 이런 오류가 발생한다면 어떨까요?
1. 데이터 라벨링은 기계 학습 및 인공지능 시스템의 성능에 중요한 역할을 하는데요. 이 작업은 아직까진 사람, 즉 데이터 라벨러가 직접 합니다. 따라서 라벨러가 고의로 틀리지 않더라도, '편향' 때문에 다양한 오류가 발생하곤 합니다.
2. 편향 오류가 발생하는 대표적인 원인은 라벨러의 '선입견’입니다. 대표적으로 인구통계학적 요소, 가령 인종, 성별, 지역, 문화적 배경 등이 판단에 영향을 미칠 수 있습니다. 또한 충분하지 못한 교육도 라벨링 오류로 이어집니다.
3. 이 문제를 가장 널리 알린 사례가 '이미지넷 사건’입니다. 이미지넷은 기계학습 분야에서 꾸준히 사용되는 대표적인 데이터셋 중 하나인데요. 사진만으로 인종이나 국가 정체성을 제멋대로 분류한다든지 성차별, 인종차별적인 라벨이 달리는 등 다양한 문제가 발견됐습니다.
4. 나아가 데이터로 사용된 사진 자체가 인종차별적이거나 성차별적이고, 심지어 동의받지 않은 개인사진까지 활용했다는 사실도 드러났습니다. 결국, 이미지넷 연구진은 문제 있는 이미지 60만건을 삭제하는 등 '역편향 작업’을 진행해야 했습니다.
5. 이렇게 라벨링 오류가 있는 데이터를 사용해서 학습한 인공지능은 부정확한 결과를 도출하거나 치명적인 편향이 발생할 확률이 증가할 수 있습니다. 최근 인공지능이 급속히 발전하면서 라벨링 된 데이터의 필요성도 증가했죠. 이런 라벨링 오류를 간과해선 안 될 겁니다.

---
사실 블로그에 올리는 건 의도하고 묶어서 올린 건 아니지만(까먹었음...) 어차피 약간 연작 성격으로 썼던 것이어서, 묶어서 올리는 것도 괜찮은 것 같습니다...

