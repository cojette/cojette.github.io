---
layout: post
title: 아직도 A/B테스트는 쉬운데 결과는 쉽지 않다면
date: 2025-07-06 22:33:00 +0900
categories: [Data, Concepts]
tags: [데이터, A/B테스트, 실험, 실험설계, 아웃스탠딩]
---


서비스를 운영하고 있는 기업들이라면 고객들이 자신들의 서비스를 더 잘 활용하여 결과적으로 더 많은 가치를 창출하기를 바랄 것이고, 이를 위해서 매일 서비스를 어떻게 더 잘 개선할 수 있을 지 고민한다. 직관적으로 접근하거나, 여러 지표를 관찰해서 어떤 부분을 어떻게 고칠 지 찾아내거나, 여러 가지 방안을 만들고 비교해가며 그 중 최선을 찾아가기도 한다.

이런 과정에 있어서 오늘날에는 많은 경우 '실험'을 활용한다. 여기서 말하는 '실험'이란 학술 연구에서 말하는 실험보다는 조금 느슨한 정의로, '아이디어와 현실을 객관적으로 비교하기 위해 데이터를 수집하고 평가하는 과정'을 통칭한다. 이는 즉, 아이디어를 통해서 일어날 것이라고 예상되는 일에 대한 가설을 만들고, 실험을 통해서 이 가설이 실제로 일어나는 지를 데이터로 확인하는 과정이다. 

이 실험의 수단으로 대표적으로 사용되는 것이 'A/B 테스트'다.  오늘날 A/B 테스트는 많은 온라인 서비스를 새로 출시하거나 업데이트 하는 경우 항상 거쳐야 하는 관문처럼 자리잡았을 정도로, 많은 기업에서 도입하고 활용하고 있는 기법이다. A/B 테스트는 각 제품의 대조군(보통 현재 사용하고 있는 방식)인 'A'보다 개선안인 'B'가 더 나은 지를 판단하기 위해, A안과 B안 중 임의로 하나씩을 고객에게 노출시킨 후, 고객의 반응을 측정하는 방식으로, 다양한 실험 방식 중에 직관적이면서 구현 기술 비용이 상대적으로 저렴하여 널리 퍼지게 되었다.  그리고 데이터에 기반한 의사결정 문화가 정착되면서, 마케팅, 제품 개발, 추천 시스템, 가격 전략 등 거의 모든 분야에서 A/B테스트는 필수적인 도구가 되었다.

심지어 어떤 기업은 A/B테스트를 신봉하는 것처럼 보이기도 한다. 이들은 A/B테스트가 자신들의 의도가 고객들에게 반영되었는지를 객관적으로 판단할 수 있는 수단이라고 단언한다. 또한 [링크드인](https://www.linkedin.com/business/marketing/blog/linkedin-ads/how-to-create-an-a-b-testing-strategy-for-your-linkedin-ads), [넷플릭스](https://netflixtechblog.com/what-is-an-a-b-test-b08cc1b57962)같은 해외의 큰 회사부터 [쏘카](https://tech.socarcorp.kr/product/2022/06/02/reservation-funnel-improvement-with-abtest.html),  [오늘의집](https://www.bucketplace.com/post/2021-10-29-%EC%98%A4%EB%8A%98%EC%9D%98%EC%A7%91-a-b-%EC%8B%A4%ED%97%98-%ED%94%8C%EB%9E%AB%ED%8F%BC-%EA%B5%AC%EC%B6%95%EA%B8%B0/) 등 국내의 수많은 스타트업까지, 실제로 A/B테스트가 서비스 개선을 가져다 준 사례가 널리 알려져 있고 그만큼 여러 기업에서 더더욱 이를 적극적으로 활용하려고 한다. 

하지만 모든 근사한 것에는 가려진 이면이 있다.  [최근 공개된 한 보고](https://vwo.com/blog/cro-industry-insights/)에 따르면  A/B 테스트 7건 중 1건은 훌륭한 전환율을 이끌어 냈다고 한다. 하지만 그렇다면 나머지 6개는 왜 이런 결과를 내지 못했을까? 이에 대해서 파악해야 이후 보다 좋은 결과를 만드는 A/B 테스트를 설계할 수 있을 것이다.

 A/B 테스트는 해결책이 아니라 해결책에 도달하기 위한 하나의 과정일 뿐이며, 모든 실험과 마찬가지로 실험을 잘 만들고 결과를 잘 분석하고 활용해야 한다. 이 과정에서 제대로 된 결과를 얻지 못할 때는 대개 최신 기술의 문제라기보다는 사람들이 놓치거나 무시하는 절차 혹은 개념의 문제일 때가 많다.

## 모호한 결과 지표 비교 

서비스의 특정 부분을 개선해서 어느 정도의 사용 시간을 달성하려는 경우, 흔히 A/B 테스트는 체류 시간이 더 높은 쪽을 선택하는 방식으로 만들어진다. 그리고 테스트 결과로 서비스 체류 시간이 조금 더 높은 특정 안을 선택하고, 해당 실험은 성공적이었다고 생각하며 해당 안을 사용한 서비스 개선이 이루어질 것이고, 실험을 진행한 사람들은 서로에게 박수를 보내며 실험이 끝난 것을 자축할 것이다. 하지만 과연 이게 끝일까?

해당 안은 사실 최적의 안이 아닐 수도 있고, 조금 더 나은 안이 있을 수도 있다. 조금만 더 개선하면 체류 시간이 좀 더 나은 안이 나올 수 있을 지도 모른다. 어차피 여러 안을 만들고 실험을 하기로 생각했다면, 좀 더 실험을 해 볼 여지가 있을 수도 있다. 하지만 이런 실험을 이미 끝내고 나면, 이 때 잘 나온 안이 다른 안보다 '객관적으로' 낫다는 성공한 기분에 쉽사리 취하게 하고, 더 나은 안을 고민할 필요가 없다고 생각하게 된다.

앞서 성공한 실험이 만약에 평균 체류 시간이 2초밖에 되지 않는 기능에 대한 것이었어서, 새롭게 개선안을 만들어서 대조를 했던 것이었다고 가정해본다. 그리고 그 개선안이 실험에서 평균 4.7초의 체류시간을 보였고, 이는 분명 원안의 200% 이상의 큰 개선이고, 실험상 통계적 유의성도 달성했다고 가정한다. 이는 분명 성공적인 결과로, 새로운 안으로 바로 서비스 개선에 들어갈 수 있을 것이다. 하지만, 이게 과연 끝일까? 이게 그저 다른 기능으로 이동하는 방식을 조금 더 어렵게 했다든가 하는 방식이라고 해도 괜찮을까? 혹은 새로운 개선안에 사람들이 적응을 못해서 나온 차이일 수도 있다. 이 기능을 '제대로' 사용했을 때 체류 시간이 15초이고, 사용자 중 50% 이상이 이 기능을 충분히 활용했을 때의 예상 평균 체류 시간이 6초라고 가정한다면, 이 두 안은 모두 더 개선할 여지가 있을 수 있다. 

이런 경우, 실험을 설계할 때 'A가 B보다 낫다' 이전에 'A가 B보다 5% 이상 낫다' 라든가 'A가 1분 이상의 체류시간이라는 목표치를 만족하면서  B보다 낫다' 같은 객관적인 목표 수치를 병행하면 도움이 될 수 있다. 목표치가 있다면 단순히 상대적으로 차이가 난다는 데에만 천착할 가능성이 낮아지고, 좀 더 많은 고민을 할 수 있게 된다. 궁극적으로는 실질적으로 더 도움이 되는 개선안을 이끌어낼 수 있을 것이다. 

## 단일 지표만 맹신하는 경우

A/B 테스트에서 측정 지표를 설정하는 데 있어서 흔히 저지르는 실수 중 하나는, 실험의 목표 지표만을 주목한다는 것이다. 많은 경우 이 지표는 '전체 고객의 전반적인 행태'를 나타내는 형태로 단순화되어 있다. 그리고 실험에서도 이런 '전반적인' 행태에 미치는 영향에만 집중한다. 이러면서 다양한 유형의 고객의 행동 방식에 대해서는 잊어버린다. 이런 경우 평균적인 고객에게 개선이 일어났어도, 어떤 유형의 고객의 수치는 크게 줄어든다거나, 혹은 특정 고객 층의 개선이 크고, 다른 고객들에게는 거의 영향을 미치지 못했다고 해도 크게 변화한 것처럼 보이게 될 수도 있다. 

예를 들어 사용자별 평균 구매 금액이 1,000원 늘어나는 신제품을 출시하는 것에 대해서 고민하고 있다고 한다면, 우리는 보통 각 사용자가 1,000원씩 구매를 더 하게 된다고 생각한다. 하지만 일부 사용자는 10,000원을 더 구매하고,  많은 사용자는 500원만큼을 덜 구매하게 된다고 해도 평균 금액은 1,000원 늘어날 수 있다. 그리고 대부분의 A/B테스트에서 사용하는 주요 지표 대시보드에서는 이런 내용에 대한 세부적인 정보는 보여주지 않는다. 

주요 지표가 소수의 대규모 고객 또는 충성고객군에 의해 좌우되는 경우, '1인당 평균 구매금액' 같이 잘 정제된 지표는 특히 오해의 소지가 있다. 의사 결정권자가 고객이 모두 동일한 행동을 하는 하나의 집단으로 생각하고 무언가를 결정한다면, 많은 일반 고객을 희생시키면서 충성 고객군에 맞춰서 제품을 최적화할 위험이 있다. 신규 고객의 유입이나 일반 고객의  소비를 늘릴 수 있는 방법을 찾는 것이 제품 성장의 기회인 경우도 많기 때문에, 이런 접근 방식은 어떤 경우에는 위험 요소가 될 수도 있다.

물론 모든 고객에게 가장 적합한 대안을 찾을 수 있다면 가장 좋겠지만, 실질적으로 그러기는 어려울 수 있다. 하지만 고객군별 다른 특성을 뭉뚱그린 상태로 무언가를 판단하는 것은 분명 위험할 수 있다.  A/B 테스트로 빠르고 편하게 답을 찾기를 바랄 수 있지만, 이런 위험을 최대한 피하려면 단일 지표만을 보기보다, 좀 더 차분하게 접근하고 실험 설계를 면밀히 검토할 필요가 있다. 사전에 충분히 고객에 대해서 이해한 후에 이를 적용해서 세부적으로 고객 군을 나누어서 살펴볼 수 있도록 실험과 결과 판단 지표를 설계한다면 이런 맹점을 피하는 데에 도움이 될 수 있을 것이다. 

## 넷플릭스와 링크드인의 대안 사례

예를 들어, 넷플릭스와 링크드인의 A/B 테스트 개선 사례를 살펴보면 다양한 방법으로 이런 부분에 대해서 고려하고 있다. 우선, 두 기업 모두 고객군을 꼼꼼하게 구분한다.

넷플릭스의 경우, 서비스 사용 환경(인터넷 속도, 사용 기기 종류 등)에 따라 고객을 분류한 후, 각 고객군 별로 실험의 효과를 따로 계산한다. 특히 앱 로딩 시간, 오류 발생 비율 같은 기술적 지표의 경우, 사용 환경에 따라서 크게 달라질 수 있으며, 이로 인해 전반적인 사용성 지표 역시 크게 차이가 날 수 있기 때문에 각 고객군을 잘 분류해두고 테스트 결과를 분석한다. 

링크드인의 A/B 테스트 플랫폼은 그룹별로 실험의 효과를 자동으로 계산한다. 예를 들어, 미국에서 잘 작동하는 기능이 인도에서는 성공적이지 않을 수 있으므로 각 국가별로 새로운 기능의 영향도를 구분해서 구한다. 혹은 일촌의 크기와 성격에 따라 특정 컨텐츠를 접할 가능성이 달라질 수 있기 때문에 소셜 네트워크의 도달 범위에 따라 사용자를 묶기도 한다.  예를 들어, 링크드인에서는 내부 분석 결과 인맥이 적은 사람들은 인맥이 풍부한 사람보다 채용 공고에 지원할 확률이 증가하는 경향이 있음을 발견했다고 한다 (인맥이 풍부한 사람들은 다른 경로를 통해 채용 공고를 접할 확률이 높다든가 하는 이유 등이 있을 수 있다). 이런 경우 채용 기능 등을 테스트 할 때는 이 두 그룹의 변화를 따로 살펴보게 되었다.

이런 구분과 실험을 통해 넷플릭스나 링크드인은 다양한 지역에서 다양하게 서비스를 제공하고 새로운 지역으로 확장할 수 있게 되었다. 예를 들어, 주로 모바일기기를 통해 인터넷에 접속하는 인도에서는 북미 시장보다 더 적은 용량의 데이터를 처리하고 필수 기능이 들어있는 가벼운 버전의 앱을 사용한다. 또한 넷플릭스는 기기별 서비스 사용량에 대한 시장별 연구를 통해 인도를 위한 모바일 전용 멤버십 요금제를 실험하고 출시하기도 했다. 

사용자 구분 뿐만이 아니라 이 두 기업의 사례들을 살펴보면 지표의 상위, 중간, 하위 백분위수와 평균값이 어떻게 변화하는지 역시 살펴볼 수 있도록 하는 등 지표를 다각도로 보기 위해  다양한 방법으로 접근한다.  넷플릭스의 경우 스트리밍 시간의 평균을 보는 대신, A안과 B안이 각각 시청 빈도가 적은 회원과 높은 회원에게  미치는 영향을 모두 확인할 수 있으며, 한 고객군쪽으로 영향도가 치우치는 정도를 같이 파악할 수 있는 측정 지표를 개발했다. 링크드인은 새로운 대안으로 인해 상위 1%의 사용자가 기여한 매출, 페이지 뷰 및 기타 주요 지표의 점유율이 증가하거나 감소하는지 여부를 같이 확인하여 변화가 고객들에게 불평등한 영향을 끼치는 지를 같이 확인한다. 이런 방식으로 사용량이 적은 고객을 희생시키면서 상위 고객에게 맞춰지는 식으로 제품을 변경하지 않도록 한다.

또한 넷플릭스의 사례에서는 A/B테스트 설계 역시 변형된 방식을 적용해 본 것도 확인할 수 있다.  인터리빙 A/B 테스트 설계라는 기법에서는 A안과 B안을 모든 실험 집단에 번갈아가며 제공한다. 이 경우 어떤 고객은 첫째 날에는 A안을, 둘째 날에는 B안을 받고, 어떤 고객은 첫 날에 B안을 받고 둘째 날에 A안을 받기도 한다.  이는 물론 고객에게 혼선을 줄 수도 있으나, 사용자의 차이로 인한 결과 문제가 덜 생기는 방법이기도 하다. 이를 통해 넷플릭스는 회원의 다양한 환경과 행동을 고려하면서 가장 유망한 안을 선택할 수 있었다. 



A/B 테스트는 고객과 시장에 대해서 제품을 개발하는 사람들이 인지하지 못했던 인사이트를 얻을 수 있는 매우 강력한 방안 중 하나이고 그만큼 널리 사용되고 있다. 하지만 새로운 경험이 일반 사용자에게 미치는 단기적인 영향에 초점을 맞추고, 빠르고 단순하게 확실한 결과를 얻고자 하는 일반적인 접근 방식은 기업이 잘못된 결론을 도출하도록 유도할 수 있다. 하지만 기존의 오류를 이해하고 이에 대한 대안적인 방법을 찾아보려고 노력하고, A/B테스트에만 과하게 의존하지 않는다면, 이 훌륭한 도구는 고객과 제품을 보다 이해하고 더 나은 방향을 찾아가는 데에 분명 도움을 줄 수 있을 것이다.

---------------------

이 글은 [연재글 다시 쓰기 프로젝트](https://cojette.github.io/posts/outst_rewriting_project/)의 일환으로 쓰게 된 글로 [이 글]([https://cojette.github.io/posts/dynamicpricing/](https://cojette.github.io/posts/metricsinabtest/) 을 다시 쓴 것입니다.
이번엔 이전에 쓴 글을 여러 면으로 수정하려고 하다가, 그다지 새로운 예제가 잘 보이지 않아서 신기했습니다. A/B테스트는 다들 분명 열심히 쓰고 있다고 했는데, 분명 여러 추가적인 글들은 있지만 눈에 띄게 새로운 인사이트를 주는 글은 찾지 못했습니다. 
그래서 그냥 이전의 원본 글을 깔끔하게 정리하는 방향으로 공개하기로 했습니다. 덕분에 시간은 좀 더 걸렸고 최근의 A/B 테스트가 궁금해졌습니다. 


-----
장기적인 비전을 가지고 즐겁게 일할 수 있는 곳을 찾고 있습니다.
관련하여 이야기를 해보고 싶으신 분, 그 외에도 다양한 이야기를 나누고자 하시는 분은 언제든 편하게 연락을 주시면 좋겠습니다. 
